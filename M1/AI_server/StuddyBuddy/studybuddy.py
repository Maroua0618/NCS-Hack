# -*- coding: utf-8 -*-
"""studybuddy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1etnglxlFgNXCOGQqxVFXUMB7tfIpsP9q
"""


# Import necessary libraries
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score, learning_curve
from sklearn.metrics import accuracy_score, f1_score
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
plt.style.use('default')
sns.set_palette("husl")

# StudyBuddyAnalyzer class
class StudyBuddyAnalyzer:
    def __init__(self):
        self.user_database = []
        self.mbti_compat = {}
        self.scaler = StandardScaler()

    def load_data(self):
        """Load data from CSV files"""
        try:
            # Load user data from users.csv


            user_df = pd.read_csv('users.csv', names=['id', 'goal', 'style', 'progress', 'mbti'], header=None)
            # Add synthetic username and profile_pic columns since they are not in the provided CSV
            user_df['username'] = [f"user_{i+1}" for i in range(len(user_df))]
            user_df['profile_pic'] = [f"/Uploads/user_{i+1}/profile.jpg" for i in range(len(user_df))]
            self.user_database = user_df.to_dict('records')
            print(f"✓ Loaded {len(self.user_database)} users from users.csv")
            print(f"Sample user keys: {self.user_database[0].keys()}")

            # Load MBTI compatibility data
            file_path="../Datasets/mbti_compatibility.csv"
            mbti_df = pd.read_csv(file_path, index_col=0)
            self.mbti_compat = mbti_df.to_dict()
            print("✓ Loaded MBTI compatibility matrix")
        except Exception as e:
            print(f"Data loading error: {e}")
            # Generate sample data with usernames and profile picture URLs if loading fails
            print("Generating sample user data...")
            goals = ["Learn Math", "Learn Programming", "Learn Design", "Learn Languages"]
            styles = ["Visual", "Auditory", "Kinesthetic", "Reading/Writing"]
            mbti_types = ["INTJ", "INTP", "ENTJ", "ENTP", "INFJ", "INFP", "ENFJ", "ENFP",
                          "ISTJ", "ISFJ", "ESTJ", "ESFJ", "ISTP", "ISFP", "ESTP", "ESFP"]
            self.user_database = [
                {
                    "id": str(i+1),
                    "goal": np.random.choice(goals),
                    "style": np.random.choice(styles),
                    "progress": np.random.randint(0, 1000),
                    "mbti": np.random.choice(mbti_types),
                    "username": f"user_{i+1}",
                    "profile_pic": f"/Uploads/user_{i+1}/profile.jpg"
                } for i in range(100)
            ]
            print("✓ Created sample data with 100 users")
            mbti_df = pd.read_csv('mbti_compatibility.csv', index_col=0)
            self.mbti_compat = mbti_df.to_dict()

    def generate_training_data(self, n_samples=1000):
        """Generate synthetic training data"""
        training_data = []
        for _ in range(n_samples):
            user_a, user_b = np.random.choice(self.user_database, 2, replace=False)
            goal_match = 1.0 if user_a.get("goal") == user_b.get("goal") else 0.0
            style_match = 1.0 if user_a.get("style") == user_b.get("style") else 0.5
            progress_diff = abs(float(user_a.get("progress", 0)) - float(user_b.get("progress", 0))) / 1000
            mbti_comp = self.mbti_compat.get(user_a.get("mbti"), {}).get(user_b.get("mbti"), 0.5)
            match_score = (goal_match * 0.4 + style_match * 0.2 + (1 - progress_diff) * 0.15 + mbti_comp * 0.25)
            noise = np.random.normal(0, 0.1)
            is_match = 1 if match_score + noise > 0.6 else 0
            training_data.append([user_a.get("id"), user_b.get("id"), goal_match, style_match, progress_diff, mbti_comp, is_match])
        X = np.array([[d[2], d[3], d[4], d[5]] for d in training_data])
        y = np.array([d[6] for d in training_data])
        print(f"✓ Generated {len(X)} training samples")
        return X, y

    def analyze_model(self, X, y):
        """Analyze and train the Decision Tree model"""
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        model = DecisionTreeClassifier(max_depth=7, random_state=42)
        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
        print("\nCross-Validation Results (5-fold):")
        print(f"Decision Tree - Mean Accuracy: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}")

        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        print("\nTest Set Results:")
        print(f"Decision Tree - Test Accuracy: {accuracy_score(y_test, y_pred):.3f}")
        print(f"Decision Tree - F1 Score: {f1_score(y_test, y_pred, average='weighted'):.3f}")

        return model

    def find_best_k_matches(self, target_user, model, k=3, min_prob=0.7):
        """Find the top k closest matches for a target user with full details"""
        probabilities = []
        for user_b in self.user_database:
            if user_b.get("id") != target_user["id"]:
                features = np.array([[1.0 if target_user["goal"] == user_b.get("goal") else 0.0,
                                     1.0 if target_user["style"] == user_b.get("style") else 0.5,
                                     abs(target_user["progress"] - float(user_b.get("progress", 0))) / 1000,
                                     self.mbti_compat.get(target_user["mbti"], {}).get(user_b.get("mbti"), 0.5)]])
                features_scaled = self.scaler.transform(features)
                prob = model.predict_proba(features_scaled)[0][1]
                probabilities.append((user_b, prob))
        sorted_matches = sorted(probabilities, key=lambda x: x[1], reverse=True)
        top_k = [(match, prob) for match, prob in sorted_matches if prob >= min_prob][:k]
        return top_k if top_k else []

    def generate_message(self, user_a, user_b):
        """Generate a message for the matched user"""
        return f"Connect with {user_b.get('username')} ({user_b.get('id')}) to study {user_b.get('goal')} together!"

# Execute the analysis
if __name__ == "__main__":
    # Initialize and load data
    analyzer = StudyBuddyAnalyzer()
    analyzer.load_data()

    # Generate and analyze training data
    X, y = analyzer.generate_training_data(n_samples=1000)
    final_model = analyzer.analyze_model(X, y)

    # Add a new user dynamically
    new_user = {
        "id": "101",
        "goal": "Learn Math",
        "style": "Visual",
        "progress": 550,
        "mbti": "INTP",
        "username": "math_enthusiast101",
        "profile_pic": "/Uploads/user_101/profile.jpg"
    }
    user_df = pd.DataFrame(analyzer.user_database)
    new_user_df = pd.DataFrame([new_user])
    user_df = pd.concat([user_df, new_user_df], ignore_index=True)
    user_df.to_csv('updated_users.csv', index=False)  # Save updated user data
    analyzer.user_database = user_df.to_dict('records')

    # Find and print the top k matches with full details
    k = 3
    top_matches = analyzer.find_best_k_matches(new_user, final_model, k=k, min_prob=0.7)
    if top_matches:
        print(f"\nTop {k} Matches for User {new_user['username']} ({new_user['id']}):")
        for i, (match, prob) in enumerate(top_matches, 1):
            message = analyzer.generate_message(new_user, match)
            print(f"\nMatch {i}:")
            print(f"  User ID: {match.get('id')}")
            print(f"  Username: {match.get('username')}")
            print(f"  Profile Picture URL: {match.get('profile_pic')}")
            print(f"  Goal: {match.get('goal')}")
            print(f"  Learning Style: {match.get('style')}")
            print(f"  Progress: {match.get('progress')}")
            print(f"  MBTI: {match.get('mbti')}")
            print(f"  Match Probability: {prob:.2f}")
            print(f"  Message: {message}")
    else:
        print("\nNo suitable matches found.")

    # Plot a simple learning curve
    train_sizes, train_scores, val_scores = learning_curve(
        final_model, analyzer.scaler.fit_transform(X), y, train_sizes=np.linspace(0.1, 1.0, 5),
        cv=5, scoring='accuracy', random_state=42
    )
    train_mean = np.mean(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    plt.figure(figsize=(8, 6))
    plt.plot(train_sizes, train_mean, label="Training Score")
    plt.plot(train_sizes, val_mean, label="Validation Score")
    plt.xlabel